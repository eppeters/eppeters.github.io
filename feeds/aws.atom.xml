<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>dinogalactic - AWS</title><link href="https://www.dinogalactic.com/" rel="alternate"></link><link href="https://www.dinogalactic.com/feeds/aws.atom.xml" rel="self"></link><id>https://www.dinogalactic.com/</id><updated>2022-06-29T19:56:00-04:00</updated><entry><title>How to Fix Docker Permissions Errors When Building a CDK Construct Library with Projen and JSII</title><link href="https://www.dinogalactic.com/how-to-fix-docker-permissions-errors-when-building-a-cdk-construct-library-with-projen-and-jsii.html" rel="alternate"></link><published>2022-06-29T14:56:00-04:00</published><updated>2022-06-29T19:56:00-04:00</updated><author><name>Eddie Peters</name></author><id>tag:www.dinogalactic.com,2022-06-29:/how-to-fix-docker-permissions-errors-when-building-a-cdk-construct-library-with-projen-and-jsii.html</id><summary type="html">&lt;p&gt;Fixing an issue with Docker socket access on GitHub actions when using projen to create an AWS CDK Construct library that is JSII compatible.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Recently I got the following error from a GitHub action run when using the &lt;a href="https://projen.io/awscdk-construct.html"&gt;&lt;code&gt;projen&lt;/code&gt; AWS CDK Construct Library project generator&lt;/a&gt; while contributing to the open-source &lt;a href="https://github.com/VerticalRelevance/control-broker/"&gt;Control Broker&lt;/a&gt;:&lt;/p&gt;
&lt;div class="codehilite" style="background: #f0f3f3"&gt;&lt;pre style="line-height: 125%"&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The CDK code that kicked off the denied Docker daemon call was the following:&lt;/p&gt;
&lt;div class="codehilite" style="background: #f0f3f3"&gt;&lt;pre style="line-height: 125%"&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span style="color: #006699; font-weight: bold"&gt;constructor&lt;/span&gt;(scope: &lt;span style="color: #007788; font-weight: bold"&gt;Construct&lt;/span&gt;, id: &lt;span style="color: #007788; font-weight: bold"&gt;string&lt;/span&gt;) {
    &lt;span style="color: #006699; font-weight: bold"&gt;super&lt;/span&gt;(scope, id);
    &lt;span style="color: #006699; font-weight: bold"&gt;this&lt;/span&gt;.handler &lt;span style="color: #555555"&gt;=&lt;/span&gt; &lt;span style="color: #006699; font-weight: bold"&gt;new&lt;/span&gt; PythonFunction(&lt;span style="color: #006699; font-weight: bold"&gt;this&lt;/span&gt;, &lt;span style="color: #CC3300"&gt;`&lt;/span&gt;&lt;span style="color: #AA0000"&gt;${&lt;/span&gt;id&lt;span style="color: #AA0000"&gt;}&lt;/span&gt;&lt;span style="color: #CC3300"&gt;CloudFormationInputHandler`&lt;/span&gt;, {
      entry: &lt;span style="color: #007788; font-weight: bold"&gt;join&lt;/span&gt;(__dirname, &lt;span style="color: #CC3300"&gt;&amp;#39;lambda-function-code/cloudformation-input-handler&amp;#39;&lt;/span&gt;),
      runtime: &lt;span style="color: #007788; font-weight: bold"&gt;Runtime.PYTHON_3_9&lt;/span&gt;,
      index&lt;span style="color: #555555"&gt;:&lt;/span&gt; &lt;span style="color: #CC3300"&gt;&amp;#39;lambda_function.py&amp;#39;&lt;/span&gt;,
      handler&lt;span style="color: #555555"&gt;:&lt;/span&gt; &lt;span style="color: #CC3300"&gt;&amp;#39;lambda_handler&amp;#39;&lt;/span&gt;,
      timeout: &lt;span style="color: #007788; font-weight: bold"&gt;Duration.seconds&lt;/span&gt;(&lt;span style="color: #FF6600"&gt;60&lt;/span&gt;),
    });
  }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Note that this &lt;code&gt;PythonFunction&lt;/code&gt; construct builds all the dependencies and things for a Python-based Lambda function into the Lambda code zip without requiring the user to do much of anything to make this happen. It is very intuitive. It does, however use Docker, which hadn't been a problem for me in other contexts.&lt;/p&gt;
&lt;div class="codehilite" style="background: #f0f3f3"&gt;&lt;pre style="line-height: 125%"&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;But I still got the above error, so I spent a long while trying to figure this out. I first discovered that one major problem was that my &lt;code&gt;build&lt;/code&gt; and &lt;code&gt;release&lt;/code&gt; steps, in my GitHub workflow files, which are generated by &lt;code&gt;projen&lt;/code&gt;, were running inside a container. This means the Docker error I was getting was coming from inside the container that was running my GitHub job. The first clue. In my case, the GitHub job container was &lt;a href="https://hub.docker.com/r/jsii/superchain/tags"&gt;&lt;code&gt;jsii/superchain&lt;/code&gt;&lt;/a&gt;:&lt;/p&gt;
&lt;div class="codehilite" style="background: #f0f3f3"&gt;&lt;pre style="line-height: 125%"&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span style="color: #0099FF; font-style: italic"&gt;# ~~ Generated by projen. To modify, edit .projenrc.js and run &amp;quot;npx projen&amp;quot;.&lt;/span&gt;

&lt;span style="color: #330099; font-weight: bold"&gt;name&lt;/span&gt;: release
&lt;span style="color: #330099; font-weight: bold"&gt;on&lt;/span&gt;:
  &lt;span style="color: #330099; font-weight: bold"&gt;push&lt;/span&gt;:
    &lt;span style="color: #330099; font-weight: bold"&gt;branches&lt;/span&gt;:
      - main
  &lt;span style="color: #330099; font-weight: bold"&gt;workflow_dispatch&lt;/span&gt;: {}
&lt;span style="color: #330099; font-weight: bold"&gt;jobs&lt;/span&gt;:
  &lt;span style="color: #330099; font-weight: bold"&gt;release&lt;/span&gt;:
    &lt;span style="color: #330099; font-weight: bold"&gt;runs-on&lt;/span&gt;: ubuntu-latest
    &lt;span style="color: #330099; font-weight: bold"&gt;permissions&lt;/span&gt;:
      &lt;span style="color: #330099; font-weight: bold"&gt;contents&lt;/span&gt;: write
    &lt;span style="color: #330099; font-weight: bold"&gt;outputs&lt;/span&gt;:
      &lt;span style="color: #330099; font-weight: bold"&gt;latest_commit&lt;/span&gt;: ${{ steps.git_remote.outputs.latest_commit }}
    &lt;span style="color: #330099; font-weight: bold"&gt;env&lt;/span&gt;:
      &lt;span style="color: #330099; font-weight: bold"&gt;CI&lt;/span&gt;: &lt;span style="color: #CC3300"&gt;&amp;quot;true&amp;quot;&lt;/span&gt;
    &lt;span style="color: #330099; font-weight: bold"&gt;steps&lt;/span&gt;:
      &lt;span style="color: #0099FF; font-style: italic"&gt;# I&amp;#39;ve remove steps just to shorten this snippet&lt;/span&gt;
      - &lt;span style="color: #330099; font-weight: bold"&gt;name&lt;/span&gt;: release
        &lt;span style="color: #330099; font-weight: bold"&gt;run&lt;/span&gt;: npx projen release
    &lt;span style="color: #330099; font-weight: bold"&gt;container&lt;/span&gt;:
      &lt;span style="color: #330099; font-weight: bold"&gt;image&lt;/span&gt;: jsii/superchain:1-buster-slim-node14
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;npx projen release&lt;/code&gt; does a lot of things, but one of the things it does is run Jest tests. This was the part that was raising the permissions error regarding the Docker daemon socket. I started troubleshooting. At first I thought it was impossible to access the docker API from within a GitHub action, but that was quickly disproven when I remembered that I had done it before in a GitHub action, albeit outside a container (i.e. on the GitHub job's host, meaning in a job that did not have the &lt;code&gt;container&lt;/code&gt; option set).&lt;/p&gt;
&lt;p&gt;I then tried another angle. I realized that the container might not have access to the Docker socket because it hadn't been mapped into the container's filesystem. I decided to change the &lt;code&gt;container&lt;/code&gt; configuration to the following:&lt;/p&gt;
&lt;div class="codehilite" style="background: #f0f3f3"&gt;&lt;pre style="line-height: 125%"&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span style="color: #330099; font-weight: bold"&gt;container&lt;/span&gt;:
    &lt;span style="color: #330099; font-weight: bold"&gt;image&lt;/span&gt;: jsii/superchain:1-buster-slim-node14
    &lt;span style="color: #330099; font-weight: bold"&gt;volumes&lt;/span&gt;:
        - /var/run/docker.sock:/var/run/docker.sock
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Surely this would work! Now the socket file actually exists within my job container.&lt;/p&gt;
&lt;div class="codehilite" style="background: #f0f3f3"&gt;&lt;pre style="line-height: 125%"&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Same error.&lt;/p&gt;
&lt;p&gt;I then stepped back for a moment and considered the error message. As is so often the case, the error message contained all the information I needed from the start, but I didn't realize that until digging around, wracking my brain, and taking a break. It's kind of like good movies -- usually the first scene contains most of the information of the movie, but you don't know how to interpret the presentation just yet. But that's enough about the philosophy of error messages.&lt;/p&gt;
&lt;p&gt;A real breakthrough came when I inspected the Dockerfile for the &lt;code&gt;jsii/superchain&lt;/code&gt; container.&lt;/p&gt;
&lt;p&gt;Critically, I found the following line within the &lt;a href="https://hub.docker.com/layers/superchain/jsii/superchain/1-buster-slim-node14/images/sha256-42f80a4fa82100da20770dbaabcae30526e30a0e263f5fa9151b2df3f701540d?context=explore"&gt;Dockerfile&lt;/a&gt;, and I immediately knew it to be the culprit.&lt;/p&gt;
&lt;div class="codehilite" style="background: #f0f3f3"&gt;&lt;pre style="line-height: 125%"&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span style="color: #006699; font-weight: bold"&gt;USER&lt;/span&gt;&lt;span style="color: #CC3300"&gt; superchain:superchain&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;A different user besides &lt;code&gt;root&lt;/code&gt; wouldn't have the permissions to access the Docker daemon, so this container image is incompatible with building Docker images on GitHub actions.&lt;/p&gt;
&lt;p&gt;But how could this be possible? Doesn't the CDK package all kinds of assets inside of Docker containers, including (like my use case) the code for Lambda functions? Indeed, it does.&lt;/p&gt;
&lt;p&gt;For a moment I thought I would have to rewrite my Lambda functions in Typescript so they could be built with &lt;code&gt;esbuild&lt;/code&gt; outside of a container, but then I got sad because that would mean that I couldn't use things like Lambda layers in my Construct, since those could also need (or at least benefit from using) Docker to build them.&lt;/p&gt;
&lt;p&gt;I also found &lt;a href="https://projen.io/api/API.html#projen-awscdk-lambdafunction"&gt;this projen project page&lt;/a&gt; that seemed to indicate that the preferred way to author Lambda functions using projen projects is to write them in Typescript. Once again, I felt that the extreme dedication to Typescript within the CDK community was at odds with its stated goal to support many runtimes. If the only way interoperability works is if you write &lt;em&gt;everything&lt;/em&gt; in Typescript, then only the users of Constructs would be able to write in any other language. But then, why would they write in some other language if, ultimately, they would only be able to share their code with users in still other languages if they had written their code in Typescript to begin with. Why not just make everyone write CDK code in Typescript, especially since &lt;a href=""&gt;you need node&lt;/a&gt; for any JSII-based project? Most importanty for my immediate need, avoiding the Docker building altogether would allow me to use my Python Lambda Function code in my &lt;/p&gt;
&lt;p&gt;I feel bad, but &lt;a href="https://blog.dmichael.be/2021/07/13/Using-Projen-for-CDK-Constructs/"&gt;this person&lt;/a&gt; kept going down the path I was on and concluded that they couldn't use Docker in GitHub actions with their projen project either, coincidentally because they used the &lt;code&gt;PythonLambdaFunction&lt;/code&gt; Construct as well:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;An interesting problem I ran into when using the PythonFunction with GitHub Actions is the construct uses Docker under the hood to install dependencies. This caused issues because Docker was unable to be called within the Action. The solution is to use the L2 Construct SingletonFunction and the local bundle option. This is well described in this AWS blog post.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;But I digress. I finally saw the light and came up with a different approach that had many benefits.&lt;/p&gt;
&lt;p&gt;Here is the test code that instantiated the &lt;code&gt;PythonLambda&lt;/code&gt; construct, though indirectly through the &lt;code&gt;new CloudFormationInputHandler()&lt;/code&gt; call:&lt;/p&gt;
&lt;div class="codehilite" style="background: #f0f3f3"&gt;&lt;pre style="line-height: 125%"&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;test(&lt;span style="color: #CC3300"&gt;&amp;#39;ControlBroker can be created and attached to a stack&amp;#39;&lt;/span&gt;, () &lt;span style="color: #555555"&gt;=&amp;gt;&lt;/span&gt; {
  &lt;span style="color: #006699; font-weight: bold"&gt;const&lt;/span&gt; stack &lt;span style="color: #555555"&gt;=&lt;/span&gt; &lt;span style="color: #006699; font-weight: bold"&gt;new&lt;/span&gt; Stack();
  &lt;span style="color: #006699; font-weight: bold"&gt;const&lt;/span&gt; api &lt;span style="color: #555555"&gt;=&lt;/span&gt; &lt;span style="color: #006699; font-weight: bold"&gt;new&lt;/span&gt; Api(stack, &lt;span style="color: #CC3300"&gt;&amp;#39;ControlbrokerApi&amp;#39;&lt;/span&gt;, {});

  &lt;span style="color: #006699; font-weight: bold"&gt;const&lt;/span&gt; cfnInputHandler &lt;span style="color: #555555"&gt;=&lt;/span&gt; &lt;span style="color: #006699; font-weight: bold"&gt;new&lt;/span&gt; CloudFormationInputHandler(stack, &lt;span style="color: #CC3300"&gt;&amp;#39;CfnInputHandler&amp;#39;&lt;/span&gt;);
  &lt;span style="color: #0099FF; font-style: italic"&gt;// ^^ The above instantiates the PythonLambda construct and kicks off the&lt;/span&gt;
  &lt;span style="color: #0099FF; font-style: italic"&gt;// ^^ Docker daemon calls during bundling (which happens BEFORE synth!)&lt;/span&gt;

  &lt;span style="color: #006699; font-weight: bold"&gt;const&lt;/span&gt; cfnInputHandlerApiBinding &lt;span style="color: #555555"&gt;=&lt;/span&gt; &lt;span style="color: #006699; font-weight: bold"&gt;new&lt;/span&gt; HttpApiBinding(&lt;span style="color: #CC3300"&gt;&amp;#39;CloudFormation&amp;#39;&lt;/span&gt;, api, cfnInputHandler);
  &lt;span style="color: #006699; font-weight: bold"&gt;const&lt;/span&gt; evalEngine &lt;span style="color: #555555"&gt;=&lt;/span&gt; &lt;span style="color: #006699; font-weight: bold"&gt;new&lt;/span&gt; OpaEvalEngine(stack, &lt;span style="color: #CC3300"&gt;&amp;#39;EvalEngine&amp;#39;&lt;/span&gt;);
  &lt;span style="color: #006699; font-weight: bold"&gt;const&lt;/span&gt; evalEngineBinding &lt;span style="color: #555555"&gt;=&lt;/span&gt; &lt;span style="color: #006699; font-weight: bold"&gt;new&lt;/span&gt; HttpApiBinding(&lt;span style="color: #CC3300"&gt;&amp;#39;EvalEngine&amp;#39;&lt;/span&gt;, api, evalEngine);
  api.setEvalEngine(evalEngine, evalEngineBinding);
  api.addInputHandler(cfnInputHandler, cfnInputHandlerApiBinding);
  &lt;span style="color: #006699; font-weight: bold"&gt;new&lt;/span&gt; ControlBroker(stack, &lt;span style="color: #CC3300"&gt;&amp;#39;TestControlBroker&amp;#39;&lt;/span&gt;, {
    api,
  });
});
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Why do I have to &lt;strong&gt;instantiate&lt;/strong&gt; my constructs that need Docker for bundling within my unit tests? Why not just mock those (or at least the bundling part) out and thereby avoid the Docker building. It would definitely cut down on test execution time, after all, and arguably actual Lambda function bundling belongs to the consumers of the Constructs rather than the Construct library itself. Perhaps a custom integration testing phase could do this bundling as part of a test deployment or something, but there was no need to do this during the packaging and release process of my Construct library. It would also reduce the number of dependencies needed to run my tests and build my library (because it would remove Docker).&lt;/p&gt;
&lt;p&gt;So I sought a way to mock out the bundling part of my Lambda functions in my unit tests.&lt;/p&gt;
&lt;p&gt;I came up with the following, which mocks the &lt;code&gt;PythonLambda&lt;/code&gt; class, skipping any bundling:&lt;/p&gt;
&lt;div class="codehilite" style="background: #f0f3f3"&gt;&lt;pre style="line-height: 125%"&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span style="color: #006699; font-weight: bold"&gt;import&lt;/span&gt; { PythonFunction } from &lt;span style="color: #CC3300"&gt;&amp;#39;@aws-cdk/aws-lambda-python-alpha&amp;#39;&lt;/span&gt;;

jest.mock(&lt;span style="color: #CC3300"&gt;&amp;#39;@aws-cdk/aws-lambda-python-alpha&amp;#39;&lt;/span&gt;);

&lt;span style="color: #006699; font-weight: bold"&gt;const&lt;/span&gt; mockedPythonFunction &lt;span style="color: #555555"&gt;=&lt;/span&gt; &lt;span style="color: #555555"&gt;&amp;lt;&lt;/span&gt;jest.Mock&lt;span style="color: #555555"&gt;&amp;lt;&lt;/span&gt;&lt;span style="color: #006699; font-weight: bold"&gt;typeof&lt;/span&gt; PythonFunction&lt;span style="color: #555555"&gt;&amp;gt;&amp;gt;&lt;/span&gt;(PythonFunction &lt;span style="color: #006699; font-weight: bold"&gt;as&lt;/span&gt; unknown);
mockedPythonFunction.mockImplementation(() &lt;span style="color: #555555"&gt;=&amp;gt;&lt;/span&gt; {
  &lt;span style="color: #006699; font-weight: bold"&gt;const&lt;/span&gt; original &lt;span style="color: #555555"&gt;=&lt;/span&gt; jest.requireActual(&lt;span style="color: #CC3300"&gt;&amp;#39;@aws-cdk/aws-lambda-python-alpha&amp;#39;&lt;/span&gt;);
  &lt;span style="color: #006699; font-weight: bold"&gt;return&lt;/span&gt; {
    ...original.PythonFunction,
    functionArn&lt;span style="color: #555555"&gt;:&lt;/span&gt; &lt;span style="color: #CC3300"&gt;&amp;#39;arn:aws:lambda:us-east-1:123456789012:function:mockfunction&amp;#39;&lt;/span&gt;,
    addPermission&lt;span style="color: #555555"&gt;:&lt;/span&gt; () &lt;span style="color: #555555"&gt;=&amp;gt;&lt;/span&gt; {},
  };
});

test(&lt;span style="color: #CC3300"&gt;&amp;#39;ControlBroker can be created and attached to a stack&amp;#39;&lt;/span&gt;, () &lt;span style="color: #555555"&gt;=&amp;gt;&lt;/span&gt; {
  &lt;span style="color: #006699; font-weight: bold"&gt;const&lt;/span&gt; stack &lt;span style="color: #555555"&gt;=&lt;/span&gt; &lt;span style="color: #006699; font-weight: bold"&gt;new&lt;/span&gt; Stack();
  &lt;span style="color: #006699; font-weight: bold"&gt;const&lt;/span&gt; api &lt;span style="color: #555555"&gt;=&lt;/span&gt; &lt;span style="color: #006699; font-weight: bold"&gt;new&lt;/span&gt; Api(stack, &lt;span style="color: #CC3300"&gt;&amp;#39;ControlbrokerApi&amp;#39;&lt;/span&gt;, {});
  &lt;span style="color: #006699; font-weight: bold"&gt;const&lt;/span&gt; cfnInputHandler &lt;span style="color: #555555"&gt;=&lt;/span&gt; &lt;span style="color: #006699; font-weight: bold"&gt;new&lt;/span&gt; CloudFormationInputHandler(stack, &lt;span style="color: #CC3300"&gt;&amp;#39;CfnInputHandler&amp;#39;&lt;/span&gt;);
  &lt;span style="color: #006699; font-weight: bold"&gt;const&lt;/span&gt; cfnInputHandlerApiBinding &lt;span style="color: #555555"&gt;=&lt;/span&gt; &lt;span style="color: #006699; font-weight: bold"&gt;new&lt;/span&gt; HttpApiBinding(&lt;span style="color: #CC3300"&gt;&amp;#39;CloudFormation&amp;#39;&lt;/span&gt;, api, cfnInputHandler);
  &lt;span style="color: #006699; font-weight: bold"&gt;const&lt;/span&gt; evalEngine &lt;span style="color: #555555"&gt;=&lt;/span&gt; &lt;span style="color: #006699; font-weight: bold"&gt;new&lt;/span&gt; OpaEvalEngine(stack, &lt;span style="color: #CC3300"&gt;&amp;#39;EvalEngine&amp;#39;&lt;/span&gt;);
  &lt;span style="color: #006699; font-weight: bold"&gt;const&lt;/span&gt; evalEngineBinding &lt;span style="color: #555555"&gt;=&lt;/span&gt; &lt;span style="color: #006699; font-weight: bold"&gt;new&lt;/span&gt; HttpApiBinding(&lt;span style="color: #CC3300"&gt;&amp;#39;EvalEngine&amp;#39;&lt;/span&gt;, api, evalEngine);
  expect(mockedPythonFunction).toHaveBeenCalled();
  api.setEvalEngine(evalEngine, evalEngineBinding);
  api.addInputHandler(cfnInputHandler, cfnInputHandlerApiBinding);
  &lt;span style="color: #006699; font-weight: bold"&gt;new&lt;/span&gt; ControlBroker(stack, &lt;span style="color: #CC3300"&gt;&amp;#39;TestControlBroker&amp;#39;&lt;/span&gt;, {
    api,
  });
});
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The particular portions of interest are those &lt;code&gt;jest&lt;/code&gt; mock-related calls and &lt;code&gt;mockedPythonFunction.mockImplementation()&lt;/code&gt;. That &lt;code&gt;mockImplementation()&lt;/code&gt; call mocks out the property &lt;code&gt;functionArn&lt;/code&gt; and the method &lt;code&gt;addPermission()&lt;/code&gt;, which I found the surrounding code needed in order to still function. For instance, without a &lt;code&gt;functionArn&lt;/code&gt; value, which of course the real non-mocked code provides, I would get the following error:&lt;/p&gt;
&lt;div class="codehilite" style="background: #f0f3f3"&gt;&lt;pre style="line-height: 125%"&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;FAIL  test/control-broker.test.ts
 ● ControlBroker can be created and attached to a stack

   Either `integrationSubtype` or `integrationUri` must be specified.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;However, with the minimal necessary mock implementation, I get the following:&lt;/p&gt;
&lt;div class="codehilite" style="background: #f0f3f3"&gt;&lt;pre style="line-height: 125%"&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;Test Suites: 2 passed, 2 total
Tests:       2 passed, 2 total
Snapshots:   0 total
Time:        4.26 s, estimated 5 s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Yay! Previously test runs took significantly longer - at least 19 seconds if the container already existed and was cached, and far longer (minutes) if not.&lt;/p&gt;
&lt;p&gt;The most important thing is that no Docker containers are created during unit test runs any longer, and I think this approach can be used by others in the future to both speed up and make their AWS CDK Construct Library unit test runs compatible with GitHub actions.&lt;/p&gt;</content><category term="AWS"></category><category term="aws"></category><category term="software development"></category><category term="cdk"></category><category term="projen"></category><category term="jsii"></category><category term="docker"></category><category term="open source"></category></entry><entry><title>How to Learn Any AWS Service in a Day</title><link href="https://www.dinogalactic.com/how-to-learn-any-aws-service-in-a-day.html" rel="alternate"></link><published>2022-06-16T14:56:00-04:00</published><updated>2022-06-16T19:56:00-04:00</updated><author><name>Eddie Peters</name></author><id>tag:www.dinogalactic.com,2022-06-16:/how-to-learn-any-aws-service-in-a-day.html</id><summary type="html">&lt;p&gt;How to Learn Any AWS Service in a Day&lt;/p&gt;</summary><content type="html">&lt;p&gt;It doesn't really matter exactly how many AWS services exist - the sheer number of them is overwhelming, and (it feels like) they add more everyday. No one person can know how to use all of them.&lt;/p&gt;
&lt;p&gt;The trick to being successful long-term in the cloud, getting new gigs, and overcoming challenges is not learning every service. In fact, the title of this article is a lie. You can't learn a service in a day, or at least not in the way you'd learn it if you implemented something in it or worked with it for a year. But very often you'll need an understanding better than "I know what AWS says this service does" but nowhere near as deep as "I know where the demons are in this service."&lt;/p&gt;
&lt;p&gt;You need a structured learning process for learning new services to this level quickly. My approach start making connections in your head between the &lt;em&gt;objects&lt;/em&gt; in a service and the &lt;em&gt;actions&lt;/em&gt; you can take with them. In short, I am simply recommending that you build a mental graph of the parts of a service and their relationships. This article will show you how to do that and where to get the information to do so. The title is just for clickbait :)&lt;/p&gt;
&lt;h2&gt;What no one tells you about AWS&lt;/h2&gt;
&lt;p&gt;AWS isn't a bunch of products that make it easier/faster to get things done. AWS is really just a bunch of HTTP APIs. These define exactly what you can and can't do in AWS. When the next Andy Jassy says "We launched service X!" he means "We launched a new HTTP API!"&lt;/p&gt;
&lt;h2&gt;What no one tells you about the docs&lt;/h2&gt;
&lt;p&gt;No one tells you that organizations, massive ones, that use AWS are somewhere on a crawl, walk, run continuum, and the fact is that their level of maturity changes from service to service and department to department. Maybe some levels of business are completely, natively built on AWS, but maybe some data analytics teams still use on-premise data warehousing backed by batch ETL and basic ad-hoc querying with no awareness of Amazon Redshift or any of AWS's other analytics offerings. But think of how AWS convinces that one lagging line-of-business to come off that on-premise workload. The two sections of the business are so different, and the two sets of people involved so different that AWS can't rely on its overall reputation to sell services. They need a quick way to convince an org's most businessy technical staff to greenlight using each service individually. AWS doesn't try to sell products to customers based on boring things such as "You can do the same thing you're doing now, but &lt;em&gt;maybe&lt;/em&gt; for cheaper!", since going to the cloud &lt;em&gt;might&lt;/em&gt; be cheaper, but it might not. AWS instead targets organizations' drives to &lt;strong&gt;grow&lt;/strong&gt; by promoting exciting long-range prospects for each service such as "Predictive modeling of data sourced from streams, data lakes, and more."&lt;/p&gt;
&lt;p&gt;Take this basic sales drive and combine it with the fact that the people writing AWS's documentation are very familiar with Redshift and all the cool things it can do, and the documentation ends up looking very top-down as a result. What this means is that the documentation barely tells you what the service &lt;em&gt;can really do&lt;/em&gt;. In other words, yeah Sagemaker can infer deeply meaningful conclusions from terrabyte datasets, but what the heck are the pieces involved in that?&lt;/p&gt;
&lt;p&gt;On the first page of a service's docs, usually called "Getting Started," the focus is on getting customers to do something that shows results really, really quickly rather than teaching the service. (Side note: the "What is &lt;em&gt;Some Service&lt;/em&gt;?" or "How &lt;em&gt;some service&lt;/em&gt; works" first-pagers are usually way better and closer to what I describe here, so read those if your service has one.) AWS wants you to see the service as a nice, packaged solution rather than a bunch of building blocks that can be hooked together in different ways (and maybe not the specific way you want!). But as any experienced AWS developer can tell you, the real work of implementation requires thinking about services almost entirely in the latter way. Interesting problems aren't covered in the Getting Started guides. They also operate at an abstracted level, sort of in the way that getting a guided tour of a building is probably fine if you're visiting on vacation, but if you're there to inspect the building for safety and soundness of design, you probably want to poke around on your own first without the layer of varnish and bias that comes with a guided tour.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: I think the &lt;a href="https://docs.aws.amazon.com/greengrass/v2/developerguide/how-it-works.html"&gt;AWS IoT Greengrass v2 "How AWS IoT Greengrass works" guide&lt;/a&gt; is a pretty good example of how some of the first docs AWS shows to you &lt;em&gt;can&lt;/em&gt; be good. I like this one particularly because of its &lt;a href="https://docs.aws.amazon.com/greengrass/v2/developerguide/how-it-works.html#concept-overview"&gt;"Key concepts for AWS IoT Greengrass"&lt;/a&gt; section that breaks down the big pieces of the Greengrass service and avoids all the abstraction that Getting Started guides necessarily introduce first.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The rest of the AWS docs sections are usually a mixture of disjointed guides of varying depth on a smattering of topics within the service. They are packed with useful information, but if you're trying to learn really quickly, they can get you mired in the depth of one topic without giving you a survey of what the service as a whole does. Sometimes they're organized as one section per feature of the service. They're often heavily console focused, which can be a fine if time-consuming and slightly misleading way of learning a service. The biggest problem with AWS's service docs is not that they won't teach you things - they will - it's that they vary so much in structure between services that your strategy for digesting one service's docs doesn't really transfer to the next. Remember - we're trying to come up with a strategy that we can use across all the services since there are a couple hundred services to learn, so we can't waste our first moments with a service poking around in possibly fruitless areas. We need the pure, unadulterated good stuff.&lt;/p&gt;
&lt;h2&gt;Breaking the docs down&lt;/h2&gt;
&lt;p&gt;The HTTP API reference documentation is the absolute best source for learning about a service, however. I cannot stress this enough: &lt;strong&gt;every tool that uses this service uses this API&lt;/strong&gt;. The only exceptions might be some behind-the-scenes APIs that the public (i.e. everyone but AWS employees) doesn't know about, but even AWS services use these API endpoints to interact with services that they depend on. Boto3, AWS CDK, any of the language SDKs, even CloudFormation and CloudFormation, use these APIs either directly or indirectly. They define absolutely and for each service the service's things and the stuff you can do to those things.&lt;/p&gt;
&lt;p&gt;The "Getting Started" documentation sections are almost story-like - they are step-by-step guides with a beginning, middle, and an end, and they're not even choose-your-own-adventure - they lead us to one end state.&lt;/p&gt;
&lt;p&gt;But once we learn how to quickly see the parts of a service and their possible connections, we can start to address interesting problems such as "What broad mitigations should my organization put in place for threats relating to Amazon Redshift?," a question that could never be answered from the top-down documentation unless a specific docs page covered it (which is possible!). Sure, months or years of experience building and operating Redshift clusters could help you answer this question quickly, but not everyone answering tough questions about an AWS service for their organization has the luxury (curse?) of having used that service for a long time already.&lt;/p&gt;
&lt;h2&gt;The process&lt;/h2&gt;
&lt;p&gt;Build a mental graph with the service's objects as nodes and its actions as connections between those nodes. Finally, fill in any gaps in your understanding or search for the answers to specific questions using the prose documentation (maybe even Getting Started!).&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Focus on the API layer first. Start learning from the most fundamental parts of the service, meaning take a bottom-up approach, not a top down one. Every service has an API Reference section &lt;a href="https://docs.aws.amazon.com/servicecatalog/latest/dg/API_Reference.html"&gt;like this one for Service Catalog&lt;/a&gt;. If you can't find it, just google "aws [Service Name] api reference."&lt;/li&gt;
&lt;li&gt;Create nodes in your mental graph as you read through the "Actions" section. Nearly every service has &lt;code&gt;Create&amp;lt;SomeObjectName&amp;gt;&lt;/code&gt; actions. Read these first to get an idea of what "things" the service involves and what kinds of attributes each of these things has. The request and response bodies will list these.&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The &lt;a href="https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-template-resource-type-ref.html"&gt;CloudFormation Resource and Property Types docs&lt;/a&gt; serve a different purpose than the service's API docs, but usually they provide a quicker overview of the types of objects in a service, since part of the CloudFormation team's job is to translate each service's objects into CloudFormation resource types, so a lot of the work of identifying things in a service is already done for you. The downsides, and the reasons I don't recommend this immediately, are that CloudFormation doesn't support every service and sometimes the strange mapping between services' APIs and CloudFormation can be more confusing than helpful. But check out this very helpful list of the &lt;a href="https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-redshift-cluster.html"&gt;CloudFormation resource types for RedShift&lt;/a&gt;. These list the types of objects in RedShift, and you don't even have to dig through the API docs!: &lt;img alt="Amazon RedShift resource types listing from the CloudFormation documentation" src="images/cloudformation-redshift-resource-types.png" /&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;After you have a solid idea of what things you can do stuff with in the service, fill in the connections between the service's nodes with the relationships between them as described by the actions' documentation. For instance, if the request body for &lt;code&gt;CreateDomain&lt;/code&gt; has a parameter called &lt;code&gt;SubnetIds&lt;/code&gt; and it's &lt;code&gt;Required: Yes&lt;/code&gt;, a &lt;code&gt;Domain&lt;/code&gt; somehow &lt;em&gt;has&lt;/em&gt; an EC2 &lt;code&gt;Subnet&lt;/code&gt;. This is an inter-service connection, but the principle still holds.&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Stop and read the paragraphs at the beginning of each action's docs. These are some of the most information-packed and direct docs sections in all of AWS.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;Begin asking "How would I do x?" Try to make a fairly rich scenario. You want it to describe an action you could actually take first thing if you started using the service.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;An example using Redshift&lt;/h2&gt;
&lt;p&gt;You can learn things just by reading the action list from the documentation. Take the &lt;a href="https://docs.aws.amazon.com/redshift/latest/APIReference/API_Operations.html"&gt;list of actions for Redshift&lt;/a&gt;, for instance:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AcceptReservedNodeExchange&lt;/li&gt;
&lt;li&gt;AddPartner&lt;/li&gt;
&lt;li&gt;AssociateDataShareConsumer&lt;/li&gt;
&lt;li&gt;AuthorizeClusterSecurityGroupIngress&lt;/li&gt;
&lt;li&gt;AuthorizeDataShare&lt;/li&gt;
&lt;li&gt;AuthorizeEndpointAccess&lt;/li&gt;
&lt;li&gt;AuthorizeSnapshotAccess&lt;/li&gt;
&lt;li&gt;BatchDeleteClusterSnapshots&lt;/li&gt;
&lt;li&gt;BatchModifyClusterSnapshots&lt;/li&gt;
&lt;li&gt;CancelResize&lt;/li&gt;
&lt;li&gt;CopyClusterSnapshot&lt;/li&gt;
&lt;li&gt;CreateAuthenticationProfile&lt;/li&gt;
&lt;li&gt;CreateCluster&lt;/li&gt;
&lt;li&gt;CreateClusterParameterGroup&lt;/li&gt;
&lt;li&gt;CreateClusterSecurityGroup&lt;/li&gt;
&lt;li&gt;CreateClusterSnapshot&lt;/li&gt;
&lt;li&gt;CreateClusterSubnetGroup&lt;/li&gt;
&lt;li&gt;CreateEndpointAccess&lt;/li&gt;
&lt;li&gt;CreateEventSubscription&lt;/li&gt;
&lt;li&gt;CreateHsmClientCertificate&lt;/li&gt;
&lt;li&gt;CreateHsmConfiguration&lt;/li&gt;
&lt;li&gt;CreateScheduledAction&lt;/li&gt;
&lt;li&gt;CreateSnapshotCopyGrant&lt;/li&gt;
&lt;li&gt;CreateSnapshotSchedule&lt;/li&gt;
&lt;li&gt;CreateTags&lt;/li&gt;
&lt;li&gt;CreateUsageLimit&lt;/li&gt;
&lt;li&gt;DeauthorizeDataShare&lt;/li&gt;
&lt;li&gt;DeleteAuthenticationProfile&lt;/li&gt;
&lt;li&gt;DeleteCluster&lt;/li&gt;
&lt;li&gt;DeleteClusterParameterGroup&lt;/li&gt;
&lt;li&gt;DeleteClusterSecurityGroup&lt;/li&gt;
&lt;li&gt;DeleteClusterSnapshot&lt;/li&gt;
&lt;li&gt;DeleteClusterSubnetGroup&lt;/li&gt;
&lt;li&gt;DeleteEndpointAccess&lt;/li&gt;
&lt;li&gt;DeleteEventSubscription&lt;/li&gt;
&lt;li&gt;DeleteHsmClientCertificate&lt;/li&gt;
&lt;li&gt;DeleteHsmConfiguration&lt;/li&gt;
&lt;li&gt;DeletePartner&lt;/li&gt;
&lt;li&gt;DeleteScheduledAction&lt;/li&gt;
&lt;li&gt;DeleteSnapshotCopyGrant&lt;/li&gt;
&lt;li&gt;DeleteSnapshotSchedule&lt;/li&gt;
&lt;li&gt;DeleteTags&lt;/li&gt;
&lt;li&gt;DeleteUsageLimit&lt;/li&gt;
&lt;li&gt;DescribeAccountAttributes&lt;/li&gt;
&lt;li&gt;DescribeAuthenticationProfiles&lt;/li&gt;
&lt;li&gt;DescribeClusterDbRevisions&lt;/li&gt;
&lt;li&gt;DescribeClusterParameterGroups&lt;/li&gt;
&lt;li&gt;DescribeClusterParameters&lt;/li&gt;
&lt;li&gt;DescribeClusters&lt;/li&gt;
&lt;li&gt;DescribeClusterSecurityGroups&lt;/li&gt;
&lt;li&gt;DescribeClusterSnapshots&lt;/li&gt;
&lt;li&gt;DescribeClusterSubnetGroups&lt;/li&gt;
&lt;li&gt;DescribeClusterTracks&lt;/li&gt;
&lt;li&gt;DescribeClusterVersions&lt;/li&gt;
&lt;li&gt;DescribeDataShares&lt;/li&gt;
&lt;li&gt;DescribeDataSharesForConsumer&lt;/li&gt;
&lt;li&gt;DescribeDataSharesForProducer&lt;/li&gt;
&lt;li&gt;DescribeDefaultClusterParameters&lt;/li&gt;
&lt;li&gt;DescribeEndpointAccess&lt;/li&gt;
&lt;li&gt;DescribeEndpointAuthorization&lt;/li&gt;
&lt;li&gt;DescribeEventCategories&lt;/li&gt;
&lt;li&gt;DescribeEvents&lt;/li&gt;
&lt;li&gt;DescribeEventSubscriptions&lt;/li&gt;
&lt;li&gt;DescribeHsmClientCertificates&lt;/li&gt;
&lt;li&gt;DescribeHsmConfigurations&lt;/li&gt;
&lt;li&gt;DescribeLoggingStatus&lt;/li&gt;
&lt;li&gt;DescribeNodeConfigurationOptions&lt;/li&gt;
&lt;li&gt;DescribeOrderableClusterOptions&lt;/li&gt;
&lt;li&gt;DescribePartners&lt;/li&gt;
&lt;li&gt;DescribeReservedNodeExchangeStatus&lt;/li&gt;
&lt;li&gt;DescribeReservedNodeOfferings&lt;/li&gt;
&lt;li&gt;DescribeReservedNodes&lt;/li&gt;
&lt;li&gt;DescribeResize&lt;/li&gt;
&lt;li&gt;DescribeScheduledActions&lt;/li&gt;
&lt;li&gt;DescribeSnapshotCopyGrants&lt;/li&gt;
&lt;li&gt;DescribeSnapshotSchedules&lt;/li&gt;
&lt;li&gt;DescribeStorage&lt;/li&gt;
&lt;li&gt;DescribeTableRestoreStatus&lt;/li&gt;
&lt;li&gt;DescribeTags&lt;/li&gt;
&lt;li&gt;DescribeUsageLimits&lt;/li&gt;
&lt;li&gt;DisableLogging&lt;/li&gt;
&lt;li&gt;DisableSnapshotCopy&lt;/li&gt;
&lt;li&gt;DisassociateDataShareConsumer&lt;/li&gt;
&lt;li&gt;EnableLogging&lt;/li&gt;
&lt;li&gt;EnableSnapshotCopy&lt;/li&gt;
&lt;li&gt;GetClusterCredentials&lt;/li&gt;
&lt;li&gt;GetReservedNodeExchangeConfigurationOptions&lt;/li&gt;
&lt;li&gt;GetReservedNodeExchangeOfferings&lt;/li&gt;
&lt;li&gt;ModifyAquaConfiguration&lt;/li&gt;
&lt;li&gt;ModifyAuthenticationProfile&lt;/li&gt;
&lt;li&gt;ModifyCluster&lt;/li&gt;
&lt;li&gt;ModifyClusterDbRevision&lt;/li&gt;
&lt;li&gt;ModifyClusterIamRoles&lt;/li&gt;
&lt;li&gt;ModifyClusterMaintenance&lt;/li&gt;
&lt;li&gt;ModifyClusterParameterGroup&lt;/li&gt;
&lt;li&gt;ModifyClusterSnapshot&lt;/li&gt;
&lt;li&gt;ModifyClusterSnapshotSchedule&lt;/li&gt;
&lt;li&gt;ModifyClusterSubnetGroup&lt;/li&gt;
&lt;li&gt;ModifyEndpointAccess&lt;/li&gt;
&lt;li&gt;ModifyEventSubscription&lt;/li&gt;
&lt;li&gt;ModifyScheduledAction&lt;/li&gt;
&lt;li&gt;ModifySnapshotCopyRetentionPeriod&lt;/li&gt;
&lt;li&gt;ModifySnapshotSchedule&lt;/li&gt;
&lt;li&gt;ModifyUsageLimit&lt;/li&gt;
&lt;li&gt;PauseCluster&lt;/li&gt;
&lt;li&gt;PurchaseReservedNodeOffering&lt;/li&gt;
&lt;li&gt;RebootCluster&lt;/li&gt;
&lt;li&gt;RejectDataShare&lt;/li&gt;
&lt;li&gt;ResetClusterParameterGroup&lt;/li&gt;
&lt;li&gt;ResizeCluster&lt;/li&gt;
&lt;li&gt;RestoreFromClusterSnapshot&lt;/li&gt;
&lt;li&gt;RestoreTableFromClusterSnapshot&lt;/li&gt;
&lt;li&gt;ResumeCluster&lt;/li&gt;
&lt;li&gt;RevokeClusterSecurityGroupIngress&lt;/li&gt;
&lt;li&gt;RevokeEndpointAccess&lt;/li&gt;
&lt;li&gt;RevokeSnapshotAccess&lt;/li&gt;
&lt;li&gt;RotateEncryptionKey&lt;/li&gt;
&lt;li&gt;UpdatePartnerStatus&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;From this list, I can quickly see that, even though the documentation says Redshift is made of Clusters and Nodes, you don't directly manage Nodes in Redshift. Applying a bit of what I know from experience in looking at AWS API documentation, I immediately realize there are no "CreateNode," "UpdateNode," or "DeleteNode" actions. I can surmise that Clusters will manage Nodes for me. Looking at the documentation for the CreateCluster endpoint and the DescribeNodeConfiguration endpoint, I see that this is indeed true and I will merely put parameters on the Cluster, and then it will manage the Nodes for me to ensure the state matches the parameters I've stated. I also see that there is no manual way to provision storage capacity via the API, though I can check on usage with "DescribeStorage." I also note that clusters can apparently be paused, rebooting, snapshotted, resized, shared through something about partnership, configured with logging, and more. I see from the CreateCluster documentation that Redshift clusters are placed in some VPC of my choosing, that I could make the very bad mistake of making my cluster publicly accessible with (apparently) one option, and more!&lt;/p&gt;
&lt;p&gt;Next, I begin poking around in the documentation for the "Create&lt;ObjectName&gt;" actions for each major object. Often these map almost exactly to the CloudFormation Objects (which is part of what makes starting with CloudFormation docs a good idea). Try to start with the most important Object first. You may not know this yet, but you can make a good guess and just keep going if you get it wrong. For Redshift, I think the most important object would probably be the Cluster, then maybe Parameter Groups, then probably Event Subscriptions and Scheduled Actions, and finally the Security Groups, Security Group Ingresses, and Endpoints, since I think I know what those do, but I'll still read them. So, I would first read the docs for "CreateCluster," then "CreateEventSubscription," and so on.&lt;/p&gt;
&lt;p&gt;Be sure to note important identifiers re-used throughout the API operations for each object type. For instance, in Redshift, the one that immediately jumps out at me is the &lt;a href="https://docs.aws.amazon.com/redshift/latest/APIReference/API_CreateCluster.html#API_CreateCluster_RequestParameters"&gt;Cluster Identifier&lt;/a&gt;: "A unique identifier for the cluster. You use this identifier to refer to the cluster for any subsequent cluster operations such as deleting or modifying. The identifier also appears in the Amazon Redshift console." This is right at the top of the CreateCluster documentation, and it will probably end up being the name that we will need most often when we are referring to specific Redshift resources -- the documentation even points this out when it talks about later operations. &lt;/p&gt;
&lt;p&gt;Knowing which identifiers exist, are required by API calls that reference existing resources, and which are easily accessible for different Objects is crucial. One of my favorite examples is EC2 Instances. EC2 is often a person's first exposure to AWS, since it's the "launch a computer in the cloud" service. They use the AWS EC2 Console Wizard and get prompted for an Instance Name. But in reality, at the API level, the Name is just a tag that is applied via the EC2 API action CreateTags, so it's not a terribly useful identifier for vanilla EC2 usage.&lt;/p&gt;
&lt;p&gt;Once you have a graph sketched out, try asking questions that fill in the gaps. For instance, "How does storage capacity work with Redshift? From EC2, I am used to compute capacity being managed by instance type and storage capacity being done in EBS or (less frequently) instance volumes." The answer is not immediately obvious via the API, so it causes me to search for the answer, which doesn't seem to be explicitly stated in the Redshift documentation. Ultimately, I find by searching "Redshift storage types" that &lt;a href="https://docs.aws.amazon.com/redshift/latest/mgmt/working-with-clusters.html#rs-node-type-info"&gt;node types in clusters determine the storage capacity&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Before actually using the service, we can ask scenario-based questions, such as "How can I query my database?" There are no obvious client or connection operations available (the &lt;code&gt;Endpoint&lt;/code&gt; operations relate to VPC endpoints per the API docs). By searching "How do I query a Redshift database?" I get the following, straightforward page &lt;a href="https://docs.aws.amazon.com/redshift/latest/mgmt/query-databases.html"&gt;"Querying a database"&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Summary&lt;/h2&gt;
&lt;p&gt;We can't learn everything from the API actions, but we can get a scaffold from which to ask better questions and start filling in the gaps with experience and prose documentation. I think this method is useful for getting up to medium speed with a service in just a couple of hours. It gives a loosely structured impression of what a service does that can then be filled in by experimentation and other reading. Beyond this initial introduction, I find that (recent) blog posts about people's first experiences trying to launch a service can be really helpful since they make daunting services more accessible and often include a little comiseration, which can be invigorating.&lt;/p&gt;</content><category term="AWS"></category><category term="aws"></category><category term="learning"></category><category term="software development"></category></entry></feed>